# Review Verification Pipeline
# 
# ç›®çš„ï¼šå°†ä¸‰é˜¶æ®µå®¡æŸ¥æœºåˆ¶å›ºåŒ–ä¸º CI è‡ªåŠ¨åŒ–æµæ°´çº¿
# 
# è§¦å‘æ¡ä»¶ï¼š
# - PR ä¿®æ”¹ simplified/ ç›®å½•ä¸‹çš„ä»£ç 
# - PR ä¿®æ”¹ test_review*.py æµ‹è¯•æ–‡ä»¶
# - PR ä¿®æ”¹ .kiro/specs/ è§„æ ¼æ–‡æ¡£
#
# æ‰§è¡Œç­–ç•¥ï¼š
# - fast-check: é»˜è®¤è¿è¡Œï¼Œ59 testsï¼Œ< 2sï¼Œå¤š Python ç‰ˆæœ¬çŸ©é˜µ
# - performance-baseline: éœ€æ‰‹åŠ¨æ‰“æ ‡ç­¾ `run-performance`ï¼Œéé˜»å¡
#
# é£é™©ç¼“è§£ï¼š
# - R-01: ç¯å¢ƒå›ºåŒ–ï¼ˆPython ç‰ˆæœ¬çŸ©é˜µ + pip cacheï¼‰
# - R-05: æ€§èƒ½æµ‹è¯•éé˜»å¡ï¼ˆcontinue-on-error: trueï¼‰

name: Review Verification Pipeline

on:
  pull_request:
    paths:
      - 'll5.2/.trunk/simplified/**'
      - 'll5.2/.trunk/simplified/tests/test_review*.py'
      - 'll5.2/.kiro/specs/**'
      - 'll5.2/scripts/verify_review.py'
      - '.trunk/simplified/**'
      - '.kiro/specs/**'
      - 'scripts/verify_review.py'

jobs:
  # ==========================================================================
  # Job 1: å¿«é€Ÿå›å½’ï¼ˆ59 tests, < 2sï¼‰- å¤šç‰ˆæœ¬çŸ©é˜µ
  # ==========================================================================
  fast-check:
    name: Fast Review Check (Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.10', '3.11', '3.12']
      fail-fast: false  # ä¸€ä¸ªç‰ˆæœ¬å¤±è´¥ä¸å½±å“å…¶ä»–ç‰ˆæœ¬
    defaults:
      run:
        working-directory: ll5.2
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-${{ matrix.python-version }}-
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pydantic pyyaml hypothesis

      - name: Run Fast Review Tests
        run: |
          python scripts/verify_review.py -v
        continue-on-error: false

      - name: Generate JUnit XML Report
        if: always()
        run: |
          python -m pytest \
            .trunk/simplified/tests/test_review_stage1.py \
            .trunk/simplified/tests/test_review_stage2.py \
            .trunk/simplified/tests/test_review_cross_stage.py \
            .trunk/simplified/tests/test_review_traceability.py \
            .trunk/simplified/tests/test_review_cli_output.py \
            .trunk/simplified/tests/test_review_performance.py \
            -m "not slow" \
            --junitxml=review_evidence_${{ matrix.python-version }}.xml \
            -v || true

      - name: Upload Fast Evidence
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: fast-evidence-py${{ matrix.python-version }}-${{ github.run_number }}
          path: ll5.2/review_evidence_${{ matrix.python-version }}.xml
          retention-days: 30

  # ==========================================================================
  # Job 2: æ€§èƒ½åŸºçº¿ï¼ˆ62 testsï¼Œä»…åœ¨ç‰¹å®šæ ‡ç­¾è§¦å‘ï¼Œéé˜»å¡ï¼‰
  # ==========================================================================
  performance-baseline:
    name: Performance Baseline Check
    runs-on: ubuntu-latest
    if: contains(github.event.pull_request.labels.*.name, 'run-performance')
    continue-on-error: true  # R-05 ç¼“è§£ï¼šæ€§èƒ½æµ‹è¯•å¤±è´¥ä¸é˜»å¡åˆå¹¶
    defaults:
      run:
        working-directory: ll5.2
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pydantic pyyaml hypothesis

      - name: Run Performance Baseline Tests
        id: perf
        run: |
          python scripts/verify_review.py --slow -v 2>&1 | tee perf_output.txt
          echo "exit_code=$?" >> $GITHUB_OUTPUT

      - name: Generate Performance Report
        if: always()
        run: |
          python -m pytest \
            .trunk/simplified/tests/test_review_performance.py \
            -m slow \
            --junitxml=performance_evidence.xml \
            -v || true

      - name: Upload Performance Evidence
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-evidence-${{ github.run_number }}
          path: |
            ll5.2/performance_evidence.xml
            ll5.2/perf_output.txt
          retention-days: 30

  # ==========================================================================
  # Job 3: å®¡æŸ¥ç»“è®ºè‡ªåŠ¨è¯„è®º
  # ==========================================================================
  review-summary:
    name: Post Review Summary
    runs-on: ubuntu-latest
    needs: [fast-check]
    if: always()
    permissions:
      pull-requests: write
    
    steps:
      - name: Download Fast Evidence (Python 3.12)
        uses: actions/download-artifact@v4
        with:
          name: fast-evidence-py3.12-${{ github.run_number }}
          path: ./evidence
        continue-on-error: true

      - name: Parse Test Results
        id: parse
        run: |
          if [ -f "./evidence/review_evidence_3.12.xml" ]; then
            echo "=== XML File Content (first 20 lines) ==="
            head -20 ./evidence/review_evidence_3.12.xml || true
            echo "=== End of XML Preview ==="
            
            # ä½¿ç”¨ Python è§£æ JUnit XMLï¼ˆæ›´å¯é ï¼‰
            python3 << 'EOF'
          import xml.etree.ElementTree as ET
          import os
          
          xml_file = "./evidence/review_evidence_3.12.xml"
          output_file = os.environ.get("GITHUB_OUTPUT", "/dev/stdout")
          
          try:
              tree = ET.parse(xml_file)
              root = tree.getroot()
              
              # JUnit XML æ ¼å¼ï¼š<testsuite tests="X" failures="Y" errors="Z" skipped="W">
              # æˆ–è€… pytest æ ¼å¼ï¼š<testsuites><testsuite ...>
              testsuite = root if root.tag == 'testsuite' else root.find('.//testsuite')
              
              if testsuite is not None:
                  tests = int(testsuite.get('tests', 0))
                  failures = int(testsuite.get('failures', 0))
                  errors = int(testsuite.get('errors', 0))
                  skipped = int(testsuite.get('skipped', 0))
              else:
                  # å°è¯•ä» testsuites æ ¹èŠ‚ç‚¹è·å–
                  tests = int(root.get('tests', 0))
                  failures = int(root.get('failures', 0))
                  errors = int(root.get('errors', 0))
                  skipped = int(root.get('skipped', 0))
              
              passed = tests - failures - errors - skipped
              status = "âœ… PASSED" if failures == 0 and errors == 0 else "âŒ FAILED"
              
              with open(output_file, "a") as f:
                  f.write(f"tests={tests}\n")
                  f.write(f"passed={passed}\n")
                  f.write(f"failures={failures}\n")
                  f.write(f"errors={errors}\n")
                  f.write(f"skipped={skipped}\n")
                  f.write(f"status={status}\n")
              
              print(f"Parsed: tests={tests}, passed={passed}, failures={failures}, errors={errors}, skipped={skipped}")
              
          except Exception as e:
              print(f"Error parsing XML: {e}")
              with open(output_file, "a") as f:
                  f.write("tests=0\n")
                  f.write("passed=0\n")
                  f.write("failures=0\n")
                  f.write("errors=0\n")
                  f.write("skipped=0\n")
                  f.write("status=âš ï¸ PARSE ERROR\n")
          EOF
          else
            echo "XML file not found: ./evidence/review_evidence_3.12.xml"
            echo "tests=0" >> $GITHUB_OUTPUT
            echo "passed=0" >> $GITHUB_OUTPUT
            echo "failures=0" >> $GITHUB_OUTPUT
            echo "errors=0" >> $GITHUB_OUTPUT
            echo "skipped=0" >> $GITHUB_OUTPUT
            echo "status=âš ï¸ NO EVIDENCE" >> $GITHUB_OUTPUT
          fi

      - name: Comment PR
        uses: actions/github-script@v7
        with:
          script: |
            const status = '${{ steps.parse.outputs.status }}';
            const tests = '${{ steps.parse.outputs.tests }}';
            const passed = '${{ steps.parse.outputs.passed }}';
            const failures = '${{ steps.parse.outputs.failures }}';
            const skipped = '${{ steps.parse.outputs.skipped }}';
            
            const body = `### ğŸ” Review Verification Summary
            
            | Metric | Value |
            |--------|-------|
            | Status | ${status} |
            | Total Tests | ${tests} |
            | Passed | ${passed} |
            | Failed | ${failures} |
            | Skipped | ${skipped} |
            
            **å®¡æŸ¥é˜¶æ®µè¦†ç›–ï¼š**
            - Stage 1: èŒƒå›´ & æ˜ å°„
            - Stage 2: å®ç° & Config-as-Policy
            - Stage 3: Traceability + CLI + Performance
            
            **Python ç‰ˆæœ¬çŸ©é˜µï¼š** 3.10, 3.11, 3.12
            
            ğŸ“¦ [Download Evidence](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
            
            > ğŸ’¡ æ€§èƒ½æµ‹è¯•éœ€æ‰‹åŠ¨æ‰“æ ‡ç­¾ \`run-performance\` è§¦å‘ï¼Œå¤±è´¥ä¸é˜»å¡åˆå¹¶
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });
